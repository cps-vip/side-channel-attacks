{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Power Analysis (CPA) Attack on AES-128 — Simulation\n",
    "**Authors:** Carter, Estelle  \n",
    "**Project:** Cyber-Physical Systems VIP — Device Security Team\n",
    "\n",
    "## Overview\n",
    "This notebook simulates a CPA attack on AES-128 *without physical hardware*. We model power consumption using the **Hamming weight** of the SubBytes output in Round 1, add Gaussian noise, and then recover the key byte-by-byte using Pearson correlation.\n",
    "\n",
    "### Attack Model\n",
    "```\n",
    "Target intermediate value:  SBox[ plaintext[j] ⊕ key[j] ]\n",
    "Power model:                HammingWeight( intermediate_value ) + noise\n",
    "Recovery method:            Pearson correlation across all 256 key guesses\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 0 — Imports & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "NUM_TRACES = 500       # Number of simulated encryptions\n",
    "NUM_BYTES  = 16        # AES-128 block size in bytes\n",
    "NOISE_STD  = 1.0       # Std deviation of Gaussian noise (try: 0.5, 1.0, 2.0, 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1 — AES S-Box Lookup Table\n",
    "The SubBytes step applies this fixed 256-element nonlinear substitution.  \n",
    "Source: FIPS 197, Section 5.1.1.  \n",
    "\n",
    "**Nothing to implement here** — just run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBOX = np.array([\n",
    "    0x63,0x7c,0x77,0x7b,0xf2,0x6b,0x6f,0xc5,0x30,0x01,0x67,0x2b,0xfe,0xd7,0xab,0x76,\n",
    "    0xca,0x82,0xc9,0x7d,0xfa,0x59,0x47,0xf0,0xad,0xd4,0xa2,0xaf,0x9c,0xa4,0x72,0xc0,\n",
    "    0xb7,0xfd,0x93,0x26,0x36,0x3f,0xf7,0xcc,0x34,0xa5,0xe5,0xf1,0x71,0xd8,0x31,0x15,\n",
    "    0x04,0xc7,0x23,0xc3,0x18,0x96,0x05,0x9a,0x07,0x12,0x80,0xe2,0xeb,0x27,0xb2,0x75,\n",
    "    0x09,0x83,0x2c,0x1a,0x1b,0x6e,0x5a,0xa0,0x52,0x3b,0xd6,0xb3,0x29,0xe3,0x2f,0x84,\n",
    "    0x53,0xd1,0x00,0xed,0x20,0xfc,0xb1,0x5b,0x6a,0xcb,0xbe,0x39,0x4a,0x4c,0x58,0xcf,\n",
    "    0xd0,0xef,0xaa,0xfb,0x43,0x4d,0x33,0x85,0x45,0xf9,0x02,0x7f,0x50,0x3c,0x9f,0xa8,\n",
    "    0x51,0xa3,0x40,0x8f,0x92,0x9d,0x38,0xf5,0xbc,0xb6,0xda,0x21,0x10,0xff,0xf3,0xd2,\n",
    "    0xcd,0x0c,0x13,0xec,0x5f,0x97,0x44,0x17,0xc4,0xa7,0x7e,0x3d,0x64,0x5d,0x19,0x73,\n",
    "    0x60,0x81,0x4f,0xdc,0x22,0x2a,0x90,0x88,0x46,0xee,0xb8,0x14,0xde,0x5e,0x0b,0xdb,\n",
    "    0xe0,0x32,0x3a,0x0a,0x49,0x06,0x24,0x5c,0xc2,0xd3,0xac,0x62,0x91,0x95,0xe4,0x79,\n",
    "    0xe7,0xc8,0x37,0x6d,0x8d,0xd5,0x4e,0xa9,0x6c,0x56,0xf4,0xea,0x65,0x7a,0xae,0x08,\n",
    "    0xba,0x78,0x25,0x2e,0x1c,0xa6,0xb4,0xc6,0xe8,0xdd,0x74,0x1f,0x4b,0xbd,0x8b,0x8a,\n",
    "    0x70,0x3e,0xb5,0x66,0x48,0x03,0xf6,0x0e,0x61,0x35,0x57,0xb9,0x86,0xc1,0x1d,0x9e,\n",
    "    0xe1,0xf8,0x98,0x11,0x69,0xd9,0x8e,0x94,0x9b,0x1e,0x87,0xe9,0xce,0x55,0x28,0xdf,\n",
    "    0x8c,0xa1,0x89,0x0d,0xbf,0xe6,0x42,0x68,0x41,0x99,0x2d,0x0f,0xb0,0x54,0xbb,0x16\n",
    "], dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2 — Helper: Hamming Weight\n",
    "\n",
    "Implement a function that returns the number of 1-bits in a byte (or a NumPy array of bytes).  \n",
    "\n",
    "**Hint:** You can use `bin(x).count('1')` for a scalar, or `np.unpackbits` for a vectorized version.  \n",
    "A fast approach: build a 256-element lookup table once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_weight(byte_array):\n",
    "    \"\"\"\n",
    "    Compute the Hamming weight (number of 1-bits) for each element.\n",
    "    \n",
    "    Args:\n",
    "        byte_array: np.ndarray of dtype uint8\n",
    "    Returns:\n",
    "        np.ndarray of ints, same shape as input\n",
    "    \"\"\"\n",
    "    # TODO: Implement this.\n",
    "    # Suggestion: precompute HW_LUT = np.array([bin(i).count('1') for i in range(256)])\n",
    "    #             then return HW_LUT[byte_array]\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3 — Simulate Trace Collection\n",
    "\n",
    "This is the core simulation step. You need to:\n",
    "\n",
    "1. **Generate a random 16-byte AES key** (`true_key`).\n",
    "2. **Generate `NUM_TRACES` random 16-byte plaintexts.**\n",
    "3. **For each plaintext, compute the \"leaked\" power value for each byte position:**\n",
    "   ```\n",
    "   intermediate = SBOX[plaintext[j] ^ key[j]]     # AddRoundKey + SubBytes\n",
    "   power_value  = HammingWeight(intermediate)      # Hamming weight model\n",
    "   ```\n",
    "4. **Add Gaussian noise** to each power value.\n",
    "\n",
    "### Expected outputs:\n",
    "- `true_key`:   shape `(16,)`, dtype `uint8`  \n",
    "- `plaintexts`: shape `(NUM_TRACES, 16)`, dtype `uint8`  \n",
    "- `traces`:     shape `(NUM_TRACES, 16)`, dtype `float64` (HW + noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_traces(num_traces, noise_std):\n",
    "    \"\"\"\n",
    "    Simulate power traces for AES-128 Round 1.\n",
    "    \n",
    "    Args:\n",
    "        num_traces: int, number of encryptions to simulate\n",
    "        noise_std:  float, standard deviation of Gaussian noise\n",
    "    Returns:\n",
    "        true_key:   np.ndarray (16,) uint8\n",
    "        plaintexts: np.ndarray (num_traces, 16) uint8\n",
    "        traces:     np.ndarray (num_traces, 16) float64\n",
    "    \"\"\"\n",
    "    # Step 1: Generate random key\n",
    "    # TODO\n",
    "    \n",
    "    # Step 2: Generate random plaintexts\n",
    "    # TODO\n",
    "    \n",
    "    # Step 3: Compute intermediate values  ->  SBOX[plaintext ^ key]\n",
    "    # TODO  (hint: NumPy XOR and SBOX indexing work element-wise on arrays)\n",
    "    \n",
    "    # Step 4: Hamming weight + noise\n",
    "    # TODO\n",
    "    \n",
    "    pass  # return true_key, plaintexts, traces\n",
    "\n",
    "\n",
    "# Generate and inspect\n",
    "# true_key, plaintexts, traces = generate_traces(NUM_TRACES, NOISE_STD)\n",
    "# print(f\"True key (hex): {true_key.tobytes().hex()}\")\n",
    "# print(f\"Plaintexts shape: {plaintexts.shape}\")\n",
    "# print(f\"Traces shape:     {traces.shape}\")\n",
    "# print(f\"Trace sample (first 5 values): {traces[0, :5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4 — CPA Attack: Single Byte\n",
    "\n",
    "Start with **byte position 0** before generalizing.\n",
    "\n",
    "For each of the 256 possible key guesses `k`:\n",
    "1. Compute the hypothetical intermediate: `SBOX[plaintexts[:, 0] ^ k]`\n",
    "2. Compute the hypothetical Hamming weight for all traces.\n",
    "3. Compute the **Pearson correlation** between the hypothesis vector and the actual trace values at byte 0.\n",
    "4. Store the correlation.\n",
    "\n",
    "The guess with the **highest absolute correlation** is your recovered key byte.\n",
    "\n",
    "**Hint:** `np.corrcoef(x, y)[0, 1]` gives the Pearson r between two 1-D arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_single_byte(plaintexts, traces, byte_index):\n",
    "    \"\"\"\n",
    "    Recover a single key byte using CPA.\n",
    "    \n",
    "    Args:\n",
    "        plaintexts: np.ndarray (num_traces, 16) uint8\n",
    "        traces:     np.ndarray (num_traces, 16) float64\n",
    "        byte_index: int, which byte position to attack (0-15)\n",
    "    Returns:\n",
    "        best_guess:    int (0-255), the recovered key byte\n",
    "        correlations:  np.ndarray (256,), correlation for each guess\n",
    "    \"\"\"\n",
    "    correlations = np.zeros(256)\n",
    "    \n",
    "    for guess in range(256):\n",
    "        # TODO: compute hypothesis and correlate\n",
    "        pass\n",
    "    \n",
    "    best_guess = np.argmax(np.abs(correlations))\n",
    "    return best_guess, correlations\n",
    "\n",
    "\n",
    "# Test on byte 0\n",
    "# guess, corrs = attack_single_byte(plaintexts, traces, 0)\n",
    "# print(f\"Byte 0 — Recovered: 0x{guess:02x}, Actual: 0x{true_key[0]:02x}, Match: {guess == true_key[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5 — Full Key Recovery\n",
    "\n",
    "Loop `attack_single_byte` over all 16 byte positions. Print each result and compare to the true key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_full_key(plaintexts, traces, true_key):\n",
    "    \"\"\"\n",
    "    Recover all 16 bytes of the AES-128 key.\n",
    "    \n",
    "    Returns:\n",
    "        recovered_key: np.ndarray (16,) uint8\n",
    "    \"\"\"\n",
    "    # TODO: loop over all 16 bytes, collect results, print progress\n",
    "    pass\n",
    "\n",
    "\n",
    "# recovered = attack_full_key(plaintexts, traces, true_key)\n",
    "# print(f\"\\nTrue key:      {true_key.tobytes().hex()}\")\n",
    "# print(f\"Recovered key: {recovered.tobytes().hex()}\")\n",
    "# print(f\"Match: {np.array_equal(true_key, recovered)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6 — Visualization: Correlation by Key Guess\n",
    "\n",
    "Plot the correlation values for all 256 guesses for a single byte. The correct key byte should show a clear spike.\n",
    "\n",
    "This is a useful diagnostic — if the spike isn't clear, you may need more traces or less noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot correlation vs key guess for byte 0\n",
    "#\n",
    "# Suggested structure:\n",
    "# fig, ax = plt.subplots(figsize=(10, 4))\n",
    "# ax.bar(range(256), corrs, width=1.0, color='steelblue')\n",
    "# ax.axvline(x=true_key[0], color='red', linestyle='--', label=f'True key byte: 0x{true_key[0]:02x}')\n",
    "# ax.set_xlabel('Key Guess')\n",
    "# ax.set_ylabel('Pearson Correlation')\n",
    "# ax.set_title('CPA — Correlation vs Key Guess (Byte 0)')\n",
    "# ax.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7 — Experiment: Traces vs. Recovery Success\n",
    "\n",
    "This is where you **characterize the information leakage** — directly relevant to the VIP project goals.\n",
    "\n",
    "Vary `NUM_TRACES` (e.g., 10, 25, 50, 100, 250, 500, 1000) at a fixed noise level and measure how many of the 16 key bytes are correctly recovered. Plot the result.\n",
    "\n",
    "**Bonus:** Repeat for different `NOISE_STD` values and overlay the curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement the traces-vs-success experiment\n",
    "#\n",
    "# Suggested structure:\n",
    "# trace_counts = [10, 25, 50, 100, 250, 500, 1000]\n",
    "# noise_levels = [0.5, 1.0, 2.0, 4.0]\n",
    "# results = {}  # noise_std -> list of (num_traces, num_correct_bytes)\n",
    "#\n",
    "# for sigma in noise_levels:\n",
    "#     results[sigma] = []\n",
    "#     for n in trace_counts:\n",
    "#         key, pts, trs = generate_traces(n, sigma)\n",
    "#         recovered = attack_full_key(pts, trs, key)\n",
    "#         correct = np.sum(recovered == key)\n",
    "#         results[sigma].append(correct)\n",
    "#\n",
    "# Then plot: x = trace_counts, y = correct bytes, one line per noise level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8 — Discussion & Next Steps\n",
    "\n",
    "Once you've completed the above, document your observations here:\n",
    "\n",
    "- How many traces were needed for full recovery at each noise level?\n",
    "- How does this compare to theoretical expectations?\n",
    "- What would change with real hardware traces? (alignment, non-Gaussian noise, algorithmic noise)\n",
    "- How could countermeasures (masking, shuffling) break this attack?\n",
    "- Connection to timing attack: what's the same principle, and what's different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your notes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
